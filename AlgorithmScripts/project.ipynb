{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILES\n",
    "ratings = pd.read_csv(\"C:/Users/19896/Downloads/archive (14)/rating.csv\")\n",
    "movies = pd.read_csv(\"C:/Users/19896/Downloads/archive (14)/movie.csv\")\n",
    "\n",
    "rating_piece = ratings.loc[:, ['userId', 'movieId', 'rating']]\n",
    "movie_piece = movies.loc[:, ['movieId', 'title', 'genres']]\n",
    "whole = pd.merge(rating_piece, movie_piece)\n",
    "whole = whole.iloc[:1_000_000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE ON HOT OF CATEGORIES\n",
    "unique = []\n",
    "for genres in whole['genres']:\n",
    "    split = genres.split('|')\n",
    "    for category in split:\n",
    "        if category not in unique:\n",
    "            unique.append(category)\n",
    "\n",
    "cat_labels = {}\n",
    "for category in unique:\n",
    "    cat_labels[category] = []\n",
    "\n",
    "for genres in whole['genres']:\n",
    "    split = genres.split('|')\n",
    "    for key in cat_labels.keys():\n",
    "        if key in split:\n",
    "            cat_labels[key].append(key)\n",
    "        else:\n",
    "            cat_labels[key].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATAFRAMES OF CATEGORY, USER RATING, MOVIE RATEING\n",
    "temp = pd.DataFrame.from_dict(cat_labels)\n",
    "temp = temp.fillna(0)\n",
    "temp = temp.where(temp == 0, 1)\n",
    "whole = pd.concat([whole, temp], axis=1)\n",
    "whole = whole.drop('genres', axis=1)\n",
    "\n",
    "categories = whole.iloc[:, 4:]\n",
    "movies = whole.loc[:, 'movieId']\n",
    "movies_cat = pd.concat([movies, categories], axis=1)\n",
    "movies_cat = movies_cat.drop_duplicates()\n",
    "movies_cat_df = movies_cat.set_index('movieId')\n",
    "movies_cat_df.to_csv('MoviesCat.csv')\n",
    "\n",
    "user_rating = whole.pivot_table(index = [\"userId\"],columns = [\"title\"],values = \"rating\")\n",
    "movie_rating = user_rating.T\n",
    "\n",
    "ur_np = user_rating.astype('float').to_numpy()\n",
    "mr_np = movie_rating.astype('float').to_numpy()\n",
    "movies_cat = movies_cat_df.astype('int').to_numpy()\n",
    "mov_np = np.where(movies_cat == 0, np.nan, movies_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DROPOUT FOR TRAIN SET TO JUDGE PROCESS\n",
    "dropout_probability = 0.25\n",
    "# Generate random mask based on dropout probability\n",
    "dropout_mask = np.random.choice([False, True], size=ur_np.shape, p=[dropout_probability, 1 - dropout_probability])\n",
    "# Apply dropout by setting selected values to nan\n",
    "ur_np_train = np.where(dropout_mask, ur_np, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19896\\AppData\\Local\\Temp\\ipykernel_6924\\61701320.py:59: RuntimeWarning: Mean of empty slice\n",
      "  completed_mat[i] = np.nanmean(ur_np[user_neighbors[i, 1:][~np.isnan(user_neighbors[i, 1:])].astype('int'), :], axis=0)\n",
      "C:\\Users\\19896\\AppData\\Local\\Temp\\ipykernel_6924\\61701320.py:59: RuntimeWarning: Mean of empty slice\n",
      "  completed_mat[i] = np.nanmean(ur_np[user_neighbors[i, 1:][~np.isnan(user_neighbors[i, 1:])].astype('int'), :], axis=0)\n",
      "C:\\Users\\19896\\AppData\\Local\\Temp\\ipykernel_6924\\61701320.py:59: RuntimeWarning: Mean of empty slice\n",
      "  completed_mat[i] = np.nanmean(ur_np[user_neighbors[i, 1:][~np.isnan(user_neighbors[i, 1:])].astype('int'), :], axis=0)\n",
      "C:\\Users\\19896\\AppData\\Local\\Temp\\ipykernel_6924\\61701320.py:59: RuntimeWarning: Mean of empty slice\n",
      "  completed_mat[i] = np.nanmean(ur_np[user_neighbors[i, 1:][~np.isnan(user_neighbors[i, 1:])].astype('int'), :], axis=0)\n"
     ]
    }
   ],
   "source": [
    "top_neighbors = [3, 4, 5, 7] #TESTED 1, 2, 3, 4, 5, 7, 10, 15, 20, 25 /50/75/100/200 ... progressivly worse #4 NEIGHBORS PERFORMED THE BEST!!!!\n",
    "#USED TO ASSIGN INDICIES TO THE NUMPY ARRAY\n",
    "index_lst = [num for num in range(ur_np_train.shape[0])]\n",
    "#ADDING THE INDICIES\n",
    "cols_windex = np.column_stack((index_lst, ur_np_train))\n",
    "user_mae_storage = {}\n",
    "for j, num_neighbors in enumerate(top_neighbors):\n",
    "    #STORE RESULTS\n",
    "    results = {}\n",
    "    #ITERATE THROUGH THE NUMPY ARRAY, GRAB EACH ROW\n",
    "    for i in range(cols_windex.shape[0]):\n",
    "        if i < 100_000: #100_000\n",
    "\n",
    "            #GRAB ROW\n",
    "            row = cols_windex[i]\n",
    "            #MASK ON NON NAN VALUES\n",
    "            mask = ~np.isnan(row)\n",
    "            #ONLY NON NAN VALUES\n",
    "            vals = row[mask]\n",
    "            #SELECTING COLUMNS BASED ON NON NAN OF THE ROW\n",
    "            cols = cols_windex[:, mask]\n",
    "            #DROP ANY ROWS THAT HAVE A NAN VALUE (ASSUMTION NOT A GOOD MATCH)\n",
    "            no_nans = cols[~np.isnan(cols).any(axis=1)]\n",
    "            #DROP IF THERE ARE MORE THAN 1000 ELIGIBLE\n",
    "            if no_nans.shape[0] > 1000:\n",
    "                no_nans = no_nans[np.random.randint(0, high=no_nans.shape[0], size=1000), :]\n",
    "            #STORE INDEX OF ROWS THAT ARE SELECTED\n",
    "            selected_idx = no_nans[:, 0]\n",
    "\n",
    "            #DIFFERENCE BETWEEN SELECTED ROWS AND LOOP ROW\n",
    "            diff = no_nans - vals\n",
    "            #TAKING THE ABSOLUTE ROW SUM OF THE VALUES (NON INDEX)\n",
    "            abs_diff = np.sum(np.abs(diff[:, 1:]), axis=1)\n",
    "\n",
    "            #ADD ACTUAL INDEX BACK TO DATAFRAME\n",
    "            idx_abs_diff = np.column_stack((selected_idx, abs_diff))\n",
    "            #MASK TO REMOVE THE ORIGINAL ROW\n",
    "            idx_abs_diff_mask = ~(idx_abs_diff[:, 0] == i)\n",
    "            #REMOVE ORIGINAL ROW\n",
    "            without_orig_col = idx_abs_diff[idx_abs_diff_mask, :]\n",
    "            #SORT ASCENDING (MIN AT TOP)\n",
    "            sorted_indicices = np.argsort(without_orig_col[:, 1])\n",
    "            #SORTED DATAFRAME\n",
    "            sorted_without_orig_col = without_orig_col[sorted_indicices]\n",
    "            #ADD TOP 20 NEIGHBORS TO THE RESULTS FOR THE KEY OF ORIG ROW INX\n",
    "            \n",
    "            #TEST 10/25/50/75/100/200\n",
    "            results[i] = sorted_without_orig_col[:num_neighbors, 0]\n",
    "\n",
    "    #RESULTS DICT TO DATAFRAME\n",
    "    results = pd.DataFrame.from_dict(results, orient='index')\n",
    "    results.to_csv('Neighbors_'  + str(num_neighbors) + '.csv')\n",
    "    #TO NUMPY ARRAY\n",
    "    user_neighbors = results.to_numpy()\n",
    "\n",
    "    #MATRIX COMPLETION BASED ON NEIGHBORS\n",
    "    completed_mat = {}\n",
    "    for i in range(user_neighbors.shape[0]):\n",
    "        completed_mat[i] = np.nanmean(ur_np[user_neighbors[i, 1:][~np.isnan(user_neighbors[i, 1:])].astype('int'), :], axis=0)\n",
    "    #SAVE COMPLETED MATRIX\n",
    "    completed_mat_results = pd.DataFrame.from_dict(completed_mat, orient='index')\n",
    "    completed_mat = completed_mat_results.to_numpy()\n",
    "    completed_mat_results.to_csv('CompletedMatrix' + str(num_neighbors) + '.csv')\n",
    "\n",
    "    #USE DROPOUT MASK TO SELECT VALUES FROM completed_mat AND CALCULATE (PENALTY FOR INCOMPLETE MATRIX BAKED IN)\n",
    "    user_mae_storage[str(num_neighbors)] = np.nanmean(np.abs(ur_np[:100_000, :][dropout_mask[:100_000, :]] - completed_mat[dropout_mask[:100_000, :]]))\n",
    "mae_storage_df = pd.DataFrame.from_dict(user_mae_storage, orient='index')\n",
    "mae_storage_df.to_csv('mae_storage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COSINE SIMULARITY MATRIX OF MOVIES\n",
    "cos_sim_ofmovies = pd.DataFrame(cosine_similarity(movies_cat_df), index=user_rating.columns, columns=user_rating.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.997247"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RESET AND DROP\n",
    "user_rating = user_rating.reset_index()\n",
    "userId = user_rating.pop('userId')\n",
    "#avg = np.nanmean(user_rating.to_numpy())\n",
    "#CRATE NP ARRAYS\n",
    "user_rating_5mask = (user_rating == 5).to_numpy()\n",
    "user_rating_4mask = (user_rating == 4).to_numpy()\n",
    "user_rating_2mask = (user_rating == 2).to_numpy()\n",
    "user_rating_1mask = (user_rating == 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS FOR MATCHING MOVIES BASED ON SIMULARITY TO MOVIES THEY LIKED (5/4) AND DISIMULARITY TO MOVIES THE DIDNT LIKE (1/2)\n",
    "def match5(user_num):\n",
    "    max_sim = 0   \n",
    "    for i, title_liked in enumerate(user_rating.loc[user_num, user_rating_5mask[user_num]].index):\n",
    "        for j, title_notseen in enumerate(user_rating.loc[user_num, ~user_rating_5mask[user_num]].index):\n",
    "            cos_sim_score = cos_sim_ofmovies.at[title_liked, title_notseen]\n",
    "            if max_sim < cos_sim_score:\n",
    "                max_sim = cos_sim_score\n",
    "                movie_based_user_recs[user_num] = (title_notseen, 5 * max_sim)\n",
    "def match4(user_num):   \n",
    "    max_sim = 0   \n",
    "    for i, title_liked in enumerate(user_rating.loc[user_num, user_rating_4mask[user_num]].index):\n",
    "        for j, title_notseen in enumerate(user_rating.loc[user_num, ~user_rating_4mask[user_num]].index):\n",
    "            cos_sim_score = cos_sim_ofmovies.at[title_liked, title_notseen]\n",
    "            if max_sim < cos_sim_score:\n",
    "                max_sim = cos_sim_score\n",
    "                movie_based_user_recs[user_num] = (title_notseen, 4 * max_sim)\n",
    "def match1(user_num):\n",
    "    min_sim = 5 \n",
    "    for i, title_disliked in enumerate(user_rating.loc[user_num, user_rating_1mask[user_num]].index):\n",
    "        for j, title_notseen in enumerate(user_rating.loc[user_num, ~user_rating_1mask[user_num]].index):\n",
    "            cos_sim_score = cos_sim_ofmovies.at[title_disliked, title_notseen]\n",
    "            if min_sim > cos_sim_score:\n",
    "                min_sim = cos_sim_score\n",
    "                movie_based_user_recs[user_num] = (title_notseen, 5 * (1 - min_sim))\n",
    "def match2(user_num):\n",
    "    min_sim = 5 \n",
    "    for i, title_disliked in enumerate(user_rating.loc[user_num, user_rating_2mask[user_num]].index):\n",
    "        for j, title_notseen in enumerate(user_rating.loc[user_num, ~user_rating_2mask[user_num]].index):\n",
    "            cos_sim_score = cos_sim_ofmovies.at[title_disliked, title_notseen]\n",
    "            if min_sim > cos_sim_score:\n",
    "                min_sim = cos_sim_score\n",
    "                movie_based_user_recs[user_num] = (title_notseen, 4 * (1 - min_sim)) \n",
    "def match3(user_num):\n",
    "    #Random Movie and data average ... no descernable features (in the scope of this project)\n",
    "    movie_based_user_recs[user_num] = (*user_rating.columns[np.random.randint(0, 32, size=1)], 3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_based_user_recs = {}\n",
    "#WANT TO FILTER FOR WHAT THEY LIKED AND USE OPPOSITE OF DISLIKE AS RESULTS\n",
    "for user_num in range(user_rating.shape[0]):\n",
    "    if user_num < 100_000:\n",
    "        if not user_rating.loc[user_num, user_rating_5mask[user_num]].index.empty:\n",
    "            match5(user_num)\n",
    "        elif not user_rating.loc[user_num, user_rating_4mask[user_num]].index.empty:\n",
    "            match4(user_num)\n",
    "        elif not user_rating.loc[user_num, user_rating_1mask[user_num]].index.empty:\n",
    "            match1(user_num)\n",
    "        elif not user_rating.loc[user_num, user_rating_2mask[user_num]].index.empty:\n",
    "            match2(user_num)\n",
    "        else:\n",
    "            match3(user_num)\n",
    "    \n",
    "user_recs_df = pd.DataFrame.from_dict(movie_based_user_recs, orient='index')\n",
    "#ADD ONE TO USER TO GET THE USER ID\n",
    "user_recs_df.index = user_recs_df.index + 1\n",
    "user_recs_df.columns = ['Movie', 'Score']\n",
    "user_recs_df.to_csv('MovieBasedUserRecs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD IN ID COLUMN\n",
    "user_recs_df['userId'] = user_recs_df.index\n",
    "#RENAME DF COLUMNS \n",
    "#BEST ONE\n",
    "completed_mat_results = pd.read_csv(\"C:/Users/19896/Downloads/vs_code/CompletedMatrix4.csv\")\n",
    "completed_mat_results = completed_mat_results.iloc[:, 1:]\n",
    "completed_mat_results.columns = cos_sim_ofmovies.columns\n",
    "completed_mat_results.index = completed_mat_results.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37803204817203123"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TAKE AVERAGE OF MOVIE REC AND USER REC, COMPUTE MAE TO COMPARE TO PURE MOVIE REC OR USER REC\n",
    "for index, row in user_recs_df.iterrows():\n",
    "    completed_mat_results.at[row['userId'], row['Movie']] = (completed_mat_results.at[row['userId'], row['Movie']] + row['Score']) / 2\n",
    "hybrid_mae_storage = np.nanmean(np.abs(ur_np[:100_000, :][dropout_mask[:100_000, :]] - completed_mat_results.to_numpy()[dropout_mask[:100_000, :]]))\n",
    "#MAE OF HYBRID STRATEGY #THIS VERSION OF A HYBRID STRATEGY PERFORMED WORSE WITH THE SAME DROPOUT MASK\n",
    "hybrid_mae_storage #0.37803204817203123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEXT STEPS -- TAKE IN MOVIE SCORES/SOMETHING LIKE, RETURN \"BEST\" MOVIE\n",
    "#MONDAY AFTER CLASS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
